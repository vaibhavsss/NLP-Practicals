{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ed886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/itami-\n",
      "[nltk_data]     macbook/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Topics Identified:\n",
      "\n",
      "Topic 1: man, good, time\n",
      "Topic 2: time, good, man\n",
      "Topic 3: time, man, good\n"
     ]
    }
   ],
   "source": [
    "# Apply topic modeling (LDA) to extract key topics from a set of documents.\n",
    "\n",
    "!pip install spacy scikit-learn nltk --quiet\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "documents = [\n",
    "    \"It is a truth universally acknowledged, that a single man in possession of a good fortune, must be in want of a wife.\",\n",
    "    \"Call me Ishmael. Some years ago‚Äînever mind how long precisely‚ÄîI thought I would sail about a little and see the watery part of the world.\",\n",
    "    \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness.\",\n",
    "    \"All happy families are alike; each unhappy family is unhappy in its own way.\",\n",
    "    \"He had never believed in ghosts until he found himself walking the halls of the empty manor at midnight.\",\n",
    "    \"The sky above the port was the color of television, tuned to a dead channel.\",\n",
    "    \"I am an invisible man. No, I am not a spook like those who haunted Edgar Allan Poe.\",\n",
    "    \"It was a bright cold day in April, and the clocks were striking thirteen.\",\n",
    "    \"Once upon a time, there was a boy who lived in a cupboard under the stairs.\",\n",
    "    \"She had always known she was different, ever since she first heard the voices no one else could hear.\"\n",
    "]\n",
    "\n",
    "cleaned_docs = []\n",
    "for doc in documents:\n",
    "    spacy_doc = nlp(doc.lower())\n",
    "    tokens = [\n",
    "        token.lemma_ for token in spacy_doc\n",
    "        if token.is_alpha and not token.is_stop and token.lemma_ not in nltk_stopwords\n",
    "    ]\n",
    "    cleaned_docs.append(\" \".join(tokens))\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=0.95, min_df=2, stop_words='english')\n",
    "X = vectorizer.fit_transform(cleaned_docs)\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=3, random_state=42)\n",
    "lda.fit(X)\n",
    "\n",
    "print(\"\\n Topics Identified:\\n\")\n",
    "words = vectorizer.get_feature_names_out()\n",
    "for idx, topic in enumerate(lda.components_):\n",
    "    top_words = [words[i] for i in topic.argsort()[-5:]]\n",
    "    print(f\"Topic {idx+1}: {', '.join(top_words)}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
